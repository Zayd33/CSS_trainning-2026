# -*- coding: utf-8 -*-
"""
Data Pipeline for ETL

"""

# Import Pandas



# Ingest these datasets into memory using read_csv and save as apps and reviews variable


# Take peak at the two data sets with print function or view in variable explorer


# View the columns, shape and data types of the data sets


# Extract Function

    # Read the file into memory
    
    # Now, print the details about the file
    
    # Print the type of each column
    
    # Finally, print a message before returning the DataFrame


# Call the function (create apps_data and reviews_data)

# Take a peek at one of the DataFrames



# Transform Function

    # Print statement for observability
    
    # Drop any duplicates from both DataFrames (also have the option to do this in-place)
    
    # Find all of the apps and reviews in the food and drink category
    
    # Filter apps by category using query
    
    # Filter reviews for matching apps
    
    # Keep only relevant review columns
    
    # Aggregate review sentiments
    
    # Merge reviews back into apps
    
    # Keep only needed columns
    
    # Convert "Reviews" to integer
    
    # Filter based on rating and review count 

    # Reset Index
   
    # Sort the top apps
    
    # Persist this DataFrame as top_apps.csv file
    
    # Print what has happened so far
    
    # Return the transformed DataFrame
    
# Call the function

# Show the data

# Import sqlite

# Load Function

    # Create a connection object
    
    # Write the data to the specified table (table_name)
    
    # Read the data, and return the result (it is to be used)
    
    # Add try/except to handle error handling and assert to check for conditions
    
# Call the function
    
    
    
    
    
    
    
